{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95db2621-a2f2-4774-9f89-9cb3545bfbdd",
   "metadata": {},
   "source": [
    "#### Testing CuPy for the first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cf4f629-e0b4-46b3-a0ef-8f123896d33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import cupy as cp\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73c8a1f0-5546-4553-94d8-19d627ddfbd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rapids/notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1c12217-c36a-4283-b2cc-af34bf5f6c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Sep 24 05:09:00 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090        Off | 00000000:09:00.0 Off |                  N/A |\n",
      "| 36%   43C    P8              27W / 370W |     26MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b823ed43-d7b4-401e-a85d-d8bf9b858e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS                           : Linux-5.15.0-58-generic-x86_64-with-glibc2.35\n",
      "Python Version               : 3.11.13\n",
      "CuPy Version                 : 13.6.0\n",
      "CuPy Platform                : NVIDIA CUDA\n",
      "NumPy Version                : 2.2.6\n",
      "SciPy Version                : 1.16.2\n",
      "Cython Build Version         : 3.1.3\n",
      "Cython Runtime Version       : None\n",
      "CUDA Root                    : /opt/conda\n",
      "nvcc PATH                    : /opt/conda/bin/nvcc\n",
      "CUDA Build Version           : 12090\n",
      "CUDA Driver Version          : 12030\n",
      "CUDA Runtime Version         : 12090 (linked to CuPy) / 12000 (locally installed)\n",
      "CUDA Extra Include Dirs      : []\n",
      "cuBLAS Version               : (available)\n",
      "cuFFT Version                : 11000\n",
      "cuRAND Version               : 10301\n",
      "cuSOLVER Version             : (11, 4, 2)\n",
      "cuSPARSE Version             : (available)\n",
      "NVRTC Version                : (12, 0)\n",
      "Thrust Version               : 200802\n",
      "CUB Build Version            : 200800\n",
      "Jitify Build Version         : <unknown>\n",
      "cuDNN Build Version          : None\n",
      "cuDNN Version                : None\n",
      "NCCL Build Version           : 22707\n",
      "NCCL Runtime Version         : 22707\n",
      "cuTENSOR Version             : None\n",
      "cuSPARSELt Build Version     : None\n",
      "Device 0 Name                : NVIDIA GeForce RTX 3090\n",
      "Device 0 Compute Capability  : 86\n",
      "Device 0 PCI Bus ID          : 0000:09:00.0\n"
     ]
    }
   ],
   "source": [
    "cp.show_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8df6bdb-dd53-4986-9224-b682e677ef5e",
   "metadata": {},
   "source": [
    "#### On the **CPU** with **NumPy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8b0bd7c-c136-4ae7-be03-29bed6695e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- On the CPU with NumPy ---\n",
    "# Create a large array on the CPU\n",
    "cpu_array = np.random.rand(10000, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c26226af-46c3-46eb-9ce6-6513ca7c635a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy execution time: 4.5097 seconds\n"
     ]
    }
   ],
   "source": [
    "# Perform a matrix multiplication on the CPU\n",
    "start_time_cpu = time.time()\n",
    "result_cpu = np.dot(cpu_array, cpu_array)\n",
    "end_time_cpu = time.time()\n",
    "print(f\"NumPy execution time: {end_time_cpu - start_time_cpu:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63022a38-f311-4003-8802-b1e4d483fdf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy execution time: 13.7193 seconds\n"
     ]
    }
   ],
   "source": [
    "# --- On the CPU with NumPy ---\n",
    "start_time_cpu = time.time()\n",
    "# Perform a matrix multiplication on the CPU\n",
    "result_cpu = np.dot(cpu_array,np.dot(cpu_array,np.dot(cpu_array, cpu_array)))\n",
    "end_time_cpu = time.time()\n",
    "print(f\"NumPy execution time: {end_time_cpu - start_time_cpu:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bdcd73-8a41-44b0-87ca-6614b70a8f8e",
   "metadata": {},
   "source": [
    "#### On the **GPU** with **CuPy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d10807ef-5a47-4794-b01f-fd8cd12974d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- On the GPU with CuPy ---\n",
    "# Now, copy the *exact same* array to the GPU\n",
    "gpu_array = cp.asarray(cpu_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a51a122-0a85-426d-aef6-9800286ff2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CuPy execution time: 0.0140 seconds\n"
     ]
    }
   ],
   "source": [
    "# Perform a matrix multiplication on the GPU\n",
    "start_time_gpu = time.time()\n",
    "result_gpu = cp.dot(gpu_array, gpu_array)\n",
    "end_time_gpu = time.time()\n",
    "print(f\"CuPy execution time: {end_time_gpu - start_time_gpu:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b49bdac7-15d2-476d-b735-8138127dfc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CuPy execution time: 0.0024 seconds\n"
     ]
    }
   ],
   "source": [
    "# Perform a matrix multiplication on the GPU\n",
    "start_time_gpu_b = time.time()\n",
    "result_gpu = cp.dot(gpu_array,cp.dot(gpu_array,cp.dot(gpu_array, gpu_array)))\n",
    "end_time_gpu_b = time.time()\n",
    "print(f\"CuPy execution time: {end_time_gpu_b - start_time_gpu_b:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a1b8ec-49b2-412c-817c-c8d88fca0ae6",
   "metadata": {},
   "source": [
    "> What?!? Anyone can explain this?!?\n",
    "\n",
    "- Your “weird result” comes from asynchronous GPU execution + warm-up overhead.\n",
    "- Without synchronization, your timer doesn’t reflect the true compute cost.\n",
    "- Add cp.cuda.Stream.null.synchronize() after the operation, and you’ll get realistic timings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f66d655f-ddb2-433c-8bbf-30c965858f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with a small matrix (500x500):\n",
      "NumPy (CPU) execution time: 0.0007 seconds\n",
      "CuPy (GPU) execution time: 0.0001 seconds\n",
      "GPU is 9.96x faster than CPU\n",
      "------------------------------\n",
      "\n",
      "Running with a larger matrix (5000x5000):\n",
      "NumPy (CPU) execution time: 0.2697 seconds\n",
      "CuPy (GPU) execution time: 0.0098 seconds\n",
      "GPU is 27.56x faster than CPU\n",
      "------------------------------\n",
      "\n",
      "Running with a very large matrix (10000x10000):\n",
      "NumPy (CPU) execution time: 2.0907 seconds\n",
      "CuPy (GPU) execution time: 0.0875 seconds\n",
      "GPU is 23.89x faster than CPU\n",
      "------------------------------\n",
      "\n",
      "Running with a very large matrix (20000x20000):\n",
      "NumPy (CPU) execution time: 17.1720 seconds\n",
      "CuPy (GPU) execution time: 0.7236 seconds\n",
      "GPU is 23.73x faster than CPU\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Function to run the comparison\n",
    "def compare_performance(matrix_size):\n",
    "    # --- Data Preparation ---\n",
    "    # Create large matrices on the CPU\n",
    "    np_array1 = np.random.rand(matrix_size, matrix_size).astype(np.float32)\n",
    "    np_array2 = np.random.rand(matrix_size, matrix_size).astype(np.float32)\n",
    "\n",
    "    # --- NumPy (CPU) Execution ---\n",
    "    start_cpu = time.time()\n",
    "    result_np = np.dot(np_array1, np_array2)\n",
    "    end_cpu = time.time()\n",
    "    cpu_time = end_cpu - start_cpu\n",
    "    print(f\"NumPy (CPU) execution time: {cpu_time:.4f} seconds\")\n",
    "\n",
    "    # --- CuPy (GPU) Execution ---\n",
    "    # Copy data from CPU to GPU memory\n",
    "    cp_array1 = cp.asarray(np_array1)\n",
    "    cp_array2 = cp.asarray(np_array2)\n",
    "\n",
    "    # Warm-up run to exclude initialization overhead\n",
    "    cp.dot(cp_array1, cp_array2)\n",
    "    cp.cuda.Stream.null.synchronize()\n",
    "\n",
    "    start_gpu = time.time()\n",
    "    result_cp = cp.dot(cp_array1, cp_array2)\n",
    "    cp.cuda.Stream.null.synchronize()  # Wait for GPU computation to finish\n",
    "    end_gpu = time.time()\n",
    "    gpu_time = end_gpu - start_gpu\n",
    "\n",
    "    # You would typically copy the result back to CPU if needed, but we don't for timing\n",
    "    # result_np_from_cp = cp.asnumpy(result_cp)\n",
    "\n",
    "    print(f\"CuPy (GPU) execution time: {gpu_time:.4f} seconds\")\n",
    "\n",
    "    # --- Results ---\n",
    "    speedup = cpu_time / gpu_time if gpu_time > 0 else float('inf')\n",
    "    print(f\"GPU is {speedup:.2f}x faster than CPU\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "# --- Run comparisons with different matrix sizes ---\n",
    "print(\"Running with a small matrix (500x500):\")\n",
    "compare_performance(500)\n",
    "print(\"\\nRunning with a larger matrix (5000x5000):\")\n",
    "compare_performance(5000)\n",
    "print(\"\\nRunning with a very large matrix (10000x10000):\")\n",
    "compare_performance(10000)\n",
    "print(\"\\nRunning with a very large matrix (20000x20000):\")\n",
    "compare_performance(20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca797180-2d9d-4914-ad6d-4754b640648f",
   "metadata": {},
   "source": [
    "> FYI: <br>\n",
    "- `np.dot` utilizes all available CPU threads for its calculations. \n",
    "- On this machine, it is configured to use 16 threads, leveraging highly optimized, multi-threaded libraries like BLAS and LAPACK.\n",
    "- Though the multi-threading, 20x times slower than GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709732c5-5e29-4600-84ea-d36446b088cf",
   "metadata": {},
   "source": [
    "#### You can use `xp` to handle both cases.\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import cupy as cp\n",
    "    # 기본 GPU (장치 0번) 초기화를 시도\n",
    "    with cp.cuda.Device(0):\n",
    "        xp = cp\n",
    "        print(\"Using CuPy. GPU device 0 is active.\")\n",
    "except (ImportError, cp.cuda.runtime.CUDARuntimeError):\n",
    "    # CuPy가 없거나, 장치 초기화에 실패하면 NumPy로 전환\n",
    "    xp = np\n",
    "    print(\"Using NumPy. CuPy not installed or device initialization failed.\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7866f7eb-a491-4026-b8db-0f7b0742dd3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
